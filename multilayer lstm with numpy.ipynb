{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4e2a98",
   "metadata": {},
   "source": [
    "### numpy implementatin of a multiplayer LSTM (https://arxiv.org/pdf/1503.04069.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeaf9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660d37b",
   "metadata": {},
   "source": [
    "Some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "841d05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    #clip to prevent overflow\n",
    "    x = np.clip(x, -709.78, 709.78)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y*(1-y)\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1-y**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a4fde",
   "metadata": {},
   "source": [
    "parameter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca495a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class param:\n",
    "    def __init__(self, shape, is_bias = False):\n",
    "        if not is_bias:\n",
    "            self.value = np.random.standard_normal(shape)*0.05\n",
    "        else:\n",
    "            self.value = np.zeros(shape)\n",
    "        self.grad = np.zeros(shape)\n",
    "        self.m = np.zeros(shape)\n",
    "        self.v = np.zeros(shape)\n",
    "    def __call__(self):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar to https://pytorch.org/docs/stable/_modules/torch/nn/utils/clip_grad.html#clip_grad_norm_\n",
    "def clip_grad_norm(grads, max_norm=0.1):\n",
    "    total_norm = 0.\n",
    "    \n",
    "    for grad in grads:\n",
    "        grad_norm = np.sum(param**2)\n",
    "        total_norm += grad_norm\n",
    "    \n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    clip_coef = max_norm / (total_norm + 1e-6)\n",
    "    \n",
    "    if clip_coef < 1:\n",
    "        for grad in grads:\n",
    "            grad *= clip_coef\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b67397a",
   "metadata": {},
   "source": [
    "pretty straight forward implementation of LSTM layer and fully connected layer\n",
    "\n",
    "update using adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd04f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, num_input, num_hidden, lr = 0.01, betas = (0.9, 0.999), epsilon = 1e-8, wd = 0.001):\n",
    "        self.num_input = num_input\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.betas = betas\n",
    "        self.epsilon = epsilon\n",
    "        self.wd = wd\n",
    "        self.update_iter = 1\n",
    "        \n",
    "        #W of shape (num_hidden, num_input)\n",
    "        self.Wz = param((num_hidden, num_input))\n",
    "        self.Wi = param((num_hidden, num_input))\n",
    "        self.Wf = param((num_hidden, num_input))\n",
    "        self.Wo = param((num_hidden, num_input))\n",
    "        \n",
    "        self.Rz = param((num_hidden, num_hidden))\n",
    "        self.Ri = param((num_hidden, num_hidden))\n",
    "        self.Rf = param((num_hidden, num_hidden))\n",
    "        self.Ro = param((num_hidden, num_hidden))\n",
    "\n",
    "        self.bz = param((num_hidden, 1),True)\n",
    "        self.bi = param((num_hidden, 1),True)\n",
    "        self.bf = param((num_hidden, 1),True)\n",
    "        self.bo = param((num_hidden, 1),True)\n",
    "        \n",
    "        self.params = [\n",
    "            self.Wz, self.Wi, self.Wf, self.Wo, \n",
    "            self.Rz, self.Ri, self.Rf, self.Ro, \n",
    "            self.bz, self.bi, self.bf, self.bo,\n",
    "        ]\n",
    "        \n",
    "        self.cache = {}\n",
    "            \n",
    "    def reset_cache(self):\n",
    "        \"\"\"\n",
    "        delta is deltas passed down from layer above\n",
    "        X, dX:\n",
    "        of shape (seq_len, num_input)\n",
    "        Z,I,F,O,C,Y, \n",
    "        dY, dO, dC, dF, dI, dZ, delta:\n",
    "        of shape (num_hidden, 1)\n",
    "        \"\"\"\n",
    "\n",
    "        for key in ['Z' ,'I' ,'F' ,'C' ,'O' ,'Y' ,'dY' ,'dO' ,'dC' ,'dF' ,'dI' ,'dZ', 'delta']:\n",
    "            self.cache[key] = [np.zeros((self.num_hidden, 1))] * (self.seq_len+1)\n",
    "        for key in ['X', 'dX']:\n",
    "            self.cache[key] = [np.zeros((self.num_input, 1))] * (self.seq_len+1)\n",
    "        \n",
    "    def forward_step(self, t):\n",
    "        xt = self.cache['X'][t]\n",
    "        Y  = self.cache['Y'][t-1]\n",
    "        C  = self.cache['C'][t-1]\n",
    "        #xt of shape (num_input,  1)\n",
    "        #Y  of shape (num_hidden, 1)\n",
    "        Z = np.tanh(self.Wz() @ xt + self.Rz() @ Y + self.bz())\n",
    "        I = sigmoid(self.Wi() @ xt + self.Ri() @ Y + self.bi())\n",
    "        F = sigmoid(self.Wf() @ xt + self.Rf() @ Y + self.bf())\n",
    "        C = Z * I + C * F\n",
    "        O = sigmoid(self.Wo() @ xt + self.Ro() @ Y + self.bo())\n",
    "        Y = np.tanh(C) * O\n",
    "\n",
    "        self.cache['Z'][t] = Z\n",
    "        self.cache['I'][t] = I\n",
    "        self.cache['F'][t] = F\n",
    "        self.cache['C'][t] = C\n",
    "        self.cache['O'][t] = O\n",
    "        self.cache['Y'][t] = Y\n",
    "        return\n",
    "\n",
    "    def backward_step(self, t):\n",
    "        dY = \\\n",
    "        self.cache['delta'][t] + \\\n",
    "        self.Rz().T @ self.cache['dZ'][t+1] + \\\n",
    "        self.Ri().T @ self.cache['dI'][t+1] + \\\n",
    "        self.Rf().T @ self.cache['dF'][t+1] + \\\n",
    "        self.Ro().T @ self.cache['dO'][t+1]\n",
    "        \n",
    "        dO = dY * np.tanh(self.cache['C'][t]) * dsigmoid(self.cache['O'][t])\n",
    "        dC = dY * self.cache['O'][t] *   dtanh(np.tanh(self.cache['C'][t])) + self.cache['dC'][t+1] * self.cache['F'][t+1]\n",
    "        dF = dC * self.cache['C'][t-1] * dsigmoid(self.cache['F'][t])\n",
    "        dI = dC * self.cache['Z'][t] *   dsigmoid(self.cache['I'][t])\n",
    "        dZ = dC * self.cache['I'][t] *   dtanh(np.tanh(self.cache['Z'][t]))\n",
    "        \n",
    "        dX = \\\n",
    "        self.Wz().T @ dZ\n",
    "        self.Wi().T @ dI\n",
    "        self.Wf().T @ dF\n",
    "        self.Wo().T @ dO\n",
    "\n",
    "        self.cache['dY'][t] = dY\n",
    "        self.cache['dO'][t] = dO\n",
    "        self.cache['dC'][t] = dC\n",
    "        self.cache['dF'][t] = dF\n",
    "        self.cache['dI'][t] = dI\n",
    "        self.cache['dZ'][t] = dZ\n",
    "        self.cache['dX'][t] = dX\n",
    "\n",
    "        self.Wz.grad += np.outer(dZ, self.cache['X'][t])\n",
    "        self.Wi.grad += np.outer(dI, self.cache['X'][t])\n",
    "        self.Wf.grad += np.outer(dF, self.cache['X'][t])\n",
    "        self.Wo.grad += np.outer(dO, self.cache['X'][t])\n",
    "\n",
    "        self.Rz.grad += np.outer(self.cache['dZ'][t+1], self.cache['Y'][t])\n",
    "        self.Ri.grad += np.outer(self.cache['dI'][t+1], self.cache['Y'][t])\n",
    "        self.Rf.grad += np.outer(self.cache['dF'][t+1], self.cache['Y'][t])\n",
    "        self.Ro.grad += np.outer(self.cache['dO'][t+1], self.cache['Y'][t])\n",
    "\n",
    "        self.bz.grad += dZ\n",
    "        self.bi.grad += dI\n",
    "        self.bf.grad += dF\n",
    "        self.bo.grad += dO\n",
    "        return\n",
    "\n",
    "    def forward(self, X):\n",
    "        #X: input of shape (seq_len, num_input)\n",
    "        seq_len, _ = X.shape\n",
    "        self.seq_len = seq_len\n",
    "        self.reset_cache()\n",
    "        for t in range(seq_len):\n",
    "            self.cache['X'][t] = X[t][:,np.newaxis]\n",
    "\n",
    "        #forward propagation\n",
    "        for t in range(seq_len):\n",
    "            self.forward_step(t)\n",
    "        return np.concatenate([ele.T for ele in self.cache['Y']][:-1], axis=0)\n",
    "\n",
    "    def backward(self, delta):\n",
    "        #delta: deltas passed down from layer above of shape (seq_len, num_hidden)\n",
    "        for t in range(self.seq_len):\n",
    "            self.cache['delta'][t] = delta[t][:,np.newaxis]\n",
    "\n",
    "        for t in reversed(range(self.seq_len)):\n",
    "            self.backward_step(t)\n",
    "        return  np.concatenate([ele.T for ele in self.cache['delta']][:-1], axis=0)\n",
    "\n",
    "    def zerograd(self):\n",
    "        for param in self.params:\n",
    "            param.grad.fill(0)\n",
    "\n",
    "    def update(self):\n",
    "        #self.clip_grad()\n",
    "        for param in self.params:\n",
    "            param.value -= self.lr * self.wd * param.value\n",
    "            param.m = self.betas[0] * param.m + (1 - self.betas[0]) * param.grad\n",
    "            param.v = self.betas[1] * param.v + (1 - self.betas[1]) * param.grad ** 2\n",
    "            m_corr = param.m / (1 - self.betas[0]**self.update_iter)\n",
    "            v_corr = param.v / (1 - self.betas[1]**self.update_iter)\n",
    "\n",
    "            param.value -= self.lr * m_corr / (np.sqrt(v_corr) + self.epsilon)\n",
    "            \n",
    "        self.update_iter += 1\n",
    "        return\n",
    "\n",
    "    def clip_grad(self):\n",
    "        grad_list = [param.grad for param in self.params]\n",
    "        clipped_grad = clip_grad_norm(grad_list)\n",
    "        for i, param in enumerate(self.params):\n",
    "            param.grad = clipped_grad[i]\n",
    "            \n",
    "class FC:\n",
    "    def __init__(self, num_input, num_output, lr = 0.01, betas = (0.9, 0.999), epsilon = 1e-8, wd = 0.001):\n",
    "        self.num_input = num_input\n",
    "        self.num_output = num_output\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.betas = betas\n",
    "        self.epsilon = epsilon\n",
    "        self.wd = wd\n",
    "        self.update_iter = 1\n",
    "        \n",
    "        #W of shape (num_hidden, num_input)\n",
    "        self.W = param((num_input, num_output))\n",
    "        self.b = param((num_output, 1),True)\n",
    "        \n",
    "        self.params = [\n",
    "            self.W,\n",
    "            self.b,\n",
    "        ]\n",
    "        \n",
    "        self.cache = {}\n",
    "            \n",
    "    def reset_cache(self):\n",
    "        \"\"\"\n",
    "        X:\n",
    "        of shape (num_feature, num_input)\n",
    "        Y:\n",
    "        of shape (num_feature, num_output)\n",
    "        \"\"\"\n",
    "        for key in ['X', 'dX']:\n",
    "            self.cache[key] = np.zeros((self.num_feature, self.num_input))\n",
    "        for key in ['Y']:\n",
    "            self.cache[key] = np.zeros((self.num_feature, self.num_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        #X: input of shape (num_feature, num_input)\n",
    "        num_feature, _ = X.shape\n",
    "        self.num_feature = num_feature\n",
    "        self.reset_cache()\n",
    "        self.cache['X'] = X\n",
    "        \n",
    "        Y = X @ self.W()\n",
    "        self.cache['Y'] = Y\n",
    "        return self.cache['Y']\n",
    "\n",
    "    def backward(self, dY):\n",
    "        #dY: deltas passed down from layer above of shape (num_feature, num_output)\n",
    "        self.W.grad += self.cache['X'].T @ dY\n",
    "        self.b.grad += np.mean(dY, axis=0, keepdims=True).T\n",
    "        \n",
    "        dX = dY @ self.W().T\n",
    "        return dX\n",
    "\n",
    "    def zerograd(self):\n",
    "        for param in self.params:\n",
    "            param.grad.fill(0)\n",
    "\n",
    "    def update(self):\n",
    "        #self.clip_grad()\n",
    "        for param in self.params:\n",
    "            param.value -= self.lr * self.wd * param.value\n",
    "            param.m = self.betas[0] * param.m + (1 - self.betas[0]) * param.grad\n",
    "            param.v = self.betas[1] * param.v + (1 - self.betas[1]) * param.grad ** 2\n",
    "            m_corr = param.m / (1 - self.betas[0]**self.update_iter)\n",
    "            v_corr = param.v / (1 - self.betas[1]**self.update_iter)\n",
    "\n",
    "            param.value -= self.lr * m_corr / (np.sqrt(v_corr) + self.epsilon)\n",
    "            \n",
    "        self.update_iter += 1\n",
    "        return\n",
    "\n",
    "    def clip_grad(self):\n",
    "        grad_list = [param.grad for param in self.params]\n",
    "        clipped_grad = clip_grad_norm(grad_list)\n",
    "        for i, param in enumerate(self.params):\n",
    "            param.grad = clipped_grad[i]\n",
    "            \n",
    "class build_model:\n",
    "    def __init__(self, num_input, num_hidden, lr = 0.01, batch_size = 8):\n",
    "        self.batch_size = batch_size\n",
    "        self.layer1 = LSTM(num_input ,num_hidden, lr = lr)\n",
    "        self.layer2 = LSTM(num_hidden ,num_hidden, lr = lr)\n",
    "        self.layer3 = LSTM(num_hidden ,num_hidden, lr = lr)\n",
    "        self.head   = FC(num_hidden,num_input, lr = lr)\n",
    "        self.cache = {}\n",
    "        \n",
    "        self.layers = [self.layer1, self.layer2, self.layer3, self.head]\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        out = X\n",
    "        for layer in self.layers:\n",
    "            out = layer.forward(out)\n",
    "        self.cache['output'] = out\n",
    "        return out\n",
    "    \n",
    "    def loss(self, label):\n",
    "        loss = 0\n",
    "        dx = np.copy(self.cache['output'])\n",
    "        for i in range(dx.shape[0]):\n",
    "            dx[i] = np.exp(dx[i]) / np.sum(np.exp(dx[i]))\n",
    "            loss += -np.log(dx[i][label[i]]) / dx.shape[0]\n",
    "            dx[i][label[i]]-=1\n",
    "        self.cache['dx'] = dx / self.batch_size\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        dx = self.cache['dx']\n",
    "        for layer in reversed(self.layers):\n",
    "            dx = layer.backward(dx)\n",
    "        return\n",
    "    \n",
    "    def zerograd(self):\n",
    "        for layer in self.layers:\n",
    "            layer.zerograd()\n",
    "\n",
    "    def update(self):\n",
    "        for layer in self.layers:\n",
    "            layer.update()\n",
    "        self.zerograd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77200323",
   "metadata": {},
   "source": [
    "data used here is Shakespeare's sonnets from https://www.gutenberg.org/ebooks/1041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ee7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/sonnet.txt') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [l.strip().lower() for l in lines]\n",
    "sonnets = []\n",
    "start = 'i'\n",
    "end = 'cliv'\n",
    "start_index = lines.index(start)\n",
    "end_index = lines.index(end)+17\n",
    "i = start_index\n",
    "while i < end_index:\n",
    "    if len(lines[i]) > 20:\n",
    "        for j in range(14):\n",
    "            sonnets.append(lines[i+j])\n",
    "        i+=14\n",
    "    else:\n",
    "        i+=1\n",
    "        \n",
    "all_ = ' '.join(sonnets)\n",
    "idx_to_char = list(set(all_))\n",
    "idx_to_char.sort()\n",
    "char_to_idx = dict()\n",
    "for i in range(len(idx_to_char)):\n",
    "    char_to_idx[idx_to_char[i]] = i\n",
    "    \n",
    "num_char = len(idx_to_char)\n",
    "max_len = 60\n",
    "all_ = all_[:(len(all_) // max_len) * max_len]\n",
    "\n",
    "sonnets = [all_[i:i+max_len] for i in range(0, len(all_), max_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b2a4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(tokens,max_len,num_char):\n",
    "    one_hot = np.zeros((max_len, num_char))\n",
    "    for i in range(len(tokens)):\n",
    "        one_hot[i][tokens[i]] = 1\n",
    "    return one_hot\n",
    "\n",
    "def tokenize_and_label(inp,max_len,num_char):\n",
    "    tokens = [char_to_idx[' ']]*max_len\n",
    "    labels = [char_to_idx[' ']]*max_len\n",
    "    \n",
    "    for i in range(len(inp)):\n",
    "        tokens[i] = char_to_idx[inp[i]]\n",
    "        if i != 0 :\n",
    "            labels[i-1] = char_to_idx[inp[i]]\n",
    "    return (onehot_encode(tokens,max_len,num_char), np.array(labels))\n",
    "\n",
    "def predict(model,max_len = 30,seed_str = ''):\n",
    "    start_index = len(seed_str)\n",
    "    tokens = [char_to_idx[' ']]*max_len\n",
    "    for i in range(len(seed_str)):\n",
    "        tokens[i] = char_to_idx[seed_str[i]]\n",
    "    while start_index+1 < max_len:\n",
    "        inp = onehot_encode(tokens,max_len,num_char)\n",
    "        out = model(inp)\n",
    "        pred = np.copy(out)\n",
    "        for i in range(pred.shape[0]):\n",
    "            pred[i] = np.exp(pred[i]) / np.sum(np.exp(pred[i]))\n",
    "        pred_token = np.argmax(pred, axis=1)[start_index-1]\n",
    "        tokens[start_index] = pred_token\n",
    "        start_index+=1\n",
    "    pred_string = ''.join([idx_to_char[token] for token in tokens if idx_to_char[token] != '='])\n",
    "    return pred_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfaf3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, hidden_size = 32, 512\n",
    "model = build_model(num_char,hidden_size,lr = 1e-4,batch_size = bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2edff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_count = 0\n",
    "num_epoches = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13553ade",
   "metadata": {},
   "source": [
    "standard training loop with gradient accumulation to simulate batched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3776ec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24\t iter: 1208\t loss: 2.5494861344586384\n",
      "a the the the the the the the the the the the the the the t \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-43d0ca126c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mpred_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(np.mean(np.abs(model.Wz.value)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-820617b4c2b6>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-820617b4c2b6>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, delta)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-820617b4c2b6>\u001b[0m in \u001b[0;36mbackward_step\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_string = ''\n",
    "for i in range(num_epoches):\n",
    "    for sonnet in sonnets:\n",
    "        tokens, labels = tokenize_and_label(sonnet, max_len, num_char)\n",
    "        \n",
    "        output = model(tokens)\n",
    "        \n",
    "        loss = model.loss(labels)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(f'epoch: {iter_count//len(sonnets)}\\t iter: {model.head.update_iter}\\t loss: {loss}')\n",
    "        print(pred_string)\n",
    "            \n",
    "        if iter_count % (1*bs) == 0:\n",
    "            pred_string = predict(model,max_len)\n",
    "        \n",
    "        model.backward()\n",
    "        if (iter_count+1)%bs ==0:\n",
    "            model.update()\n",
    "        \n",
    "        iter_count+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
